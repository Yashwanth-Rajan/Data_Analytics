{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "VqjUMRpL5E3R",
        "outputId": "b5bf1f08-a362-4130-ee17-0918d6cfebce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the best data science course. Data science is popular'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "# !pip install nltk\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "import string\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# remove punctuation\n",
        "string.punctuation\n",
        "text=\"The cats are Playing! with each other ,and the mice.\"\n",
        "def punc(text):\n",
        "  punc=\"\".join([i for i in text if i not in string.punctuation])\n",
        "  return (punc)\n",
        "data=punc(text)\n",
        "data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ht5zktiO5TjH",
        "outputId": "09e2e840-ec0a-4fdd-ba37-eb685c204e11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The cats are Playing with each other and the mice'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lower case\n",
        "data=data.lower()\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "FrKYaXVL5fxr",
        "outputId": "3111f280-a13e-4227-f3d7-bb09d3cefe54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the cats are playing with each other and the mice'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # tokenization\n",
        "# print(data.split())"
      ],
      "metadata": {
        "id": "YAI9Oa_98f2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenization\n",
        "from nltk.tokenize import word_tokenize\n",
        "w=word_tokenize(data)\n",
        "print(w)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2tU-M4L_8pS",
        "outputId": "acdf7922-0213-4205-b615-5f44d5287f55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['the', 'cats', 'are', 'playing', 'with', 'each', 'other', 'and', 'the', 'mice']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# stop words\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "def remove_stopwords(text):\n",
        "\tstop_words = set(stopwords.words(\"english\"))\n",
        "\tword_tokens = w\n",
        "\ttxt = [i for i in word_tokens if i not in stop_words]\n",
        "\treturn txt\n",
        "\n",
        "# text=\"the best data science course. Data science is popular\"\n",
        "words=remove_stopwords(remove_stopwords)\n",
        "words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncmjWK4NA7BG",
        "outputId": "a4df1c77-c118-4dcc-f4cc-c3b4b2f433f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cats', 'playing', 'mice']"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import nltk\n",
        "# from nltk.stem import PorterStemmer\n",
        "\n",
        "# nltk.download('punkt')\n",
        "\n",
        "# Initialize the stemmer\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "# Example text\n",
        "text = \"The cats are playing with each other and the mice.\"\n",
        "\n",
        "# Tokenize the text into words\n",
        "words = nltk.word_tokenize(text)\n",
        "\n",
        "# Perform stemming\n",
        "stemmed_words = [stemmer.stem(word) for word in words]\n",
        "\n",
        "# Join the stemmed words back into a sentence\n",
        "stemmed_text = ' '.join(stemmed_words)\n",
        "\n",
        "print(\"Original Text:\", text)\n",
        "print(\"Stemmed Text:\", stemmed_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsbOqQWOkuie",
        "outputId": "be456a3b-9a69-4db2-f967-ede154fae6db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text: The cats are playing with each other and the mice.\n",
            "Stemmed Text: the cat are play with each other and the mice .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# stemming\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "stemmer= PorterStemmer()\n",
        "# w=word_tokenize(text)\n",
        "stems = [stemmer.stem(word) for word in words]\n",
        "stems"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHElpdM9SIVs",
        "outputId": "4a920cd6-f004-48a2-8c4a-f3a1ce8a3a61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['best', 'data', 'scienc', 'cours', 'data', 'scienc', 'popular']"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lemmatization\n",
        "from nltk.stem import \tWordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "w=word_tokenize(text)\n",
        "lemmas = [lemmatizer.lemmatize(word) for word in w]\n",
        "lemmas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMAhI7mtH-m6",
        "outputId": "bcb432d7-7da4-43cc-8669-f4c714f98bc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The',\n",
              " 'cat',\n",
              " 'are',\n",
              " 'playing',\n",
              " 'with',\n",
              " 'each',\n",
              " 'other',\n",
              " 'and',\n",
              " 'the',\n",
              " 'mouse',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AM4nukPEkAuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Initialize the lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Example text\n",
        "text = \"The cats are playing with each other and the mice.\"\n",
        "\n",
        "# Tokenize the text into words\n",
        "words = nltk.word_tokenize(text)\n",
        "\n",
        "# Define a function to convert POS tags to WordNet tags\n",
        "def get_wordnet_pos(treebank_tag):\n",
        "    if treebank_tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif treebank_tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif treebank_tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif treebank_tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN\n",
        "\n",
        "# Perform lemmatization\n",
        "lemmatized_words = []\n",
        "for word, pos in nltk.pos_tag(words):\n",
        "    wordnet_pos = get_wordnet_pos(pos)\n",
        "    lemmatized_word = lemmatizer.lemmatize(word, pos=wordnet_pos)\n",
        "    lemmatized_words.append(lemmatized_word)\n",
        "\n",
        "# Join the lemmatized words back into a sentence\n",
        "lemmatized_text = ' '.join(lemmatized_words)\n",
        "\n",
        "print(\"Original Text:\", text)\n",
        "print(\"Lemmatized Text:\", lemmatized_text)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWZkIxAOIihK",
        "outputId": "2c431e1c-71fe-4337-a9b5-265473b349fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text: The cats are playing with each other and the mice.\n",
            "Lemmatized Text: The cat be play with each other and the mouse .\n"
          ]
        }
      ]
    }
  ]
}